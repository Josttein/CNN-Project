\startsection[title={\em Convolutional} Neural Networks]
A convolutional neural network is an evolution of a classical multilayer percepetron network.
Recall the basic principle underpinning how a normal neuron in a neural network is supposed to work.
The neuron is supposed to \quote{look} for features in its input data.
If the neuron \quote{thinks} that those features are present in the input data it \quote{fires}.
Otherwise the neuron does not fire.

In a classical multilayer percepetron network this is implemented in the following way.
Each neuron contains a vector of weights, a bias and an activation function.
The input to the neuron---which must be a vector of equal length to the neuron's own weight vector---is combined with the neuron's weight vector using the dot product.
The neuron's bias is added onto the result which in turn is passed to the activation function which finally determines if the neuron \quote{fires} or not.

Using several layers of neurons one can achive quite remarkable results using this implementation of a neural network.
However, a multilayer percepetron is inherently limited.
The major problem is that neurons in these kinds of networks only accept input that is in the form of a vector.
This means that for applications where it is not natural for the input to be in a vector format, say image recognition, the input first has to be translated to a vector format.
Usually this results in a loss of information contained in the input.
In the typical case of image recongition, the input is in the form of one or more arrays of two dimentions.
For a multilayer percepetron to treat this input, the images has to be \quote{flattend} into a vector of one dimention before it can be passed on to the network.
This procedure eliminates some of the pixel relations in the image.
To deduce this, consider the process of reconstructing a flattend image.
If the image's dimentions prior to being flattend is not known, it is impossible, without the aid of pattern recognition, to reconstruct the image and be sure the reconstruction is equal to the original image.

To fix this problem, we can use a \quote{simple} solution.
Instead of having the neuron contain a vector of weights, let it have an array of weights.
If we change the neuron's vector of weights into an array, we also need to change the operation that is used to combine the weights with the input (which in a neuron of a multilayer percepetron is the dot product).
There are two things to consider here.
The purpose of the weights is to look for features or {\em patterns} in the input---by emphasizing or deemphasizing certain aspects---and the operation must reflect this purpose of the weights.
Furthermore, the result of the operation should be a single number which, in a sense, representes the neurons \quote{initial} confidence that the feature it is looking for is present in the input.
The operation which does both of these things is the {\em Hadamard product}.
The Hadamard product can be viewed as an extension of the dot product to two dimentional arrays.
It combines two arrays---of the same dimentions---by multiplying corresponding entries together and summing the results.
Which is precisly what the dot product does with two vectors.

The Hadamard product (${\rm Hp}$) of two matricies $A,B$ with entries $a_{i,j},b_{i,j}$ of equal dimentions is
\startplaceformula[reference=hdprod]
\startformula
{\rm Hp}(A,B) = \sum_{j} \sum_{i} a_{i,j} \cdot b_{i,j}
\stopformula
\stopplaceformula

\indentation
Another thing we need to take into account is the dimentions of our new weight array.
If we were to proceed analogically to how a multilayer percepetron works, the array should have the same size as the input to the neuron.
\quote{Connecting} each value in the input to an individual weight in the neuron.
But this approach means that each neuron, in principle, looks for a single feature in the entire input at once.
A more refined approach, is to let the neuron's weight array be smaller in size than its input.
Instead of applying the weight array (using the Hadamard product) to the entire input at once, we apply it (still using the Hadamard product) to portions of the input seperately.
Intuitivly, this means that the weight arrays are \quote{scanned} across the entire input image.
This allows the neuron to be trained to look for a single feature, such as a \quote{sharp edge} or a \quote{round corner}, in multiple areas of the input.
The result of this method will no longer be a single number representing how \quote{initialy} confident the neuron is that a particular feature is present in the input {\em\bf as a whole}.
Rather, the result becomes a {\em feature map}.
Another two dimentional array which representes how \quote{initialy} confident the neuron is that a particular feature is present in {\em\bf specific locations} of the input.

Going one step further, we can allow the neuron to treat inputs of not only a single two dimentional array, but several two dimentional arrays.
A typical example where the input would consists of several interlinked two dimentional arrays is RGB images.
An RGB image consists of three arrays of pixel values (numbers) that desribe how red, green and blue an image is in each pixel.
The number of interlinked two dimentional arrays present in the input, is known as the number of {\em channels} that the input has.
In order for our neuron to treat inputs with more than one channel we let the neuron have as many channels as the input.
That is to say, we equip the neuron with a weight array for each channel in the input.
For each channel the weight arrays are applied to the input (using Hadamard) and the result in each channel is combined to form a final single feature map.

A neural network which makes use of layers of neurons of this kind, is a convolutional neural network.
The multi-channel two dimentional arrays of weights inside each such neuron is called the neuron's {\em kernel} or {\em filter}.
Why are these neural networks called convolutional neural networks?
That will be explained in the next section.

\startsubsection[title=The convolutional neuron]
Let us start this section with a simple convolutional neuron.
The neuron's kernel consists of a single weight matrix (one channel), some bias and some activation function.
Consequently, the input that this neuron accepts is any one channel two dimentional array of size greater than its kernel.
The process of calcuating the neurons \quote{initial} confidence that the feature it is looking for is present in the input is illustrated by Figure~\in[conv-operation] on page~\at[conv-operation].
Figure~\in[conv-operation] illustrates how the kernel \quote{scans} the entire input array to compute the feature map.
Let us construct the general formula for this feature map.
We will denote the feature map, kernel and input as $F$, $K$ and $M$ respectivly.
They are two dimentional arrays and their individual entries will be denoted as $F(i,j)$ where $i$ is the row number and $j$ the column (e.g.\ $M(2,3)$ is the entry in the second row, third column of $M$).
The horisontal lengths and vertical lengths of the kernel and input will be denoted using a $h$ and $v$ prefixes (e.g.\ $hK$ is the horisontal length of the kernel).
A typical MNIST image of dimentions $28{\rm x}28$ as the input, will have $hM = vM = 28$.
The entries in the inital $\color[red]{F}$ are produced by applying the Hadamard product (eq.~\in[hdprod]) to each area of dimentions $hK{\rm x}vK$.
Thus the entry at row $i'$ and column $j'$ is

\startplaceformula
\startformula
\color[red]{F}(i',j') = \sum_{i = 1}^{vM} \sum_{j = 1}^{hM} K(i,j) \cdot M(i' + i, j + j')
\stopformula
\stopplaceformula

If we add a bias $b$ to this filter, the formula becomes

\startplaceformula
\startformula
\color[red]{F}(i',j') = \sum_{i = 1}^{vM} \sum_{j = 1}^{hM} \Bigl( K(i,j) \cdot M(i' + i, j + j') + b \Bigr)
\stopformula
\stopplaceformula

Lastly, the final output feature map $F$ of the filter is produced by sending all of these entries through an activation function.

\startplaceformula
\startformula
F(i',j') = {\rm activation} \left( \sum_{i = 1}^{vM} \sum_{j = 1}^{hM} \Bigl( K(i,j) \cdot M(i' + i, j + j') + b \Bigr) \right)
\stopformula
\stopplaceformula

\startplacefigure[reference=conv-operation,
                   title={The basic forward operation of a convolutional layer},
                   location=top]
\startcombination[3*3]
{\externalfigure[./Images/conv-0.jpg][width=.3\textwidth]}{}
{\externalfigure[./Images/conv-1.jpg][width=.3\textwidth]}{}
{\externalfigure[./Images/conv-2.jpg][width=.3\textwidth]}{}
{\externalfigure[./Images/conv-3.jpg][width=.3\textwidth]}{}
{\externalfigure[./Images/conv-4.jpg][width=.3\textwidth]}{}
{\externalfigure[./Images/conv-5.jpg][width=.3\textwidth]}{}
{\externalfigure[./Images/conv-6.jpg][width=.3\textwidth]}{}
{\externalfigure[./Images/conv-7.jpg][width=.3\textwidth]}{}
{\externalfigure[./Images/conv-8.jpg][width=.3\textwidth]}{}
\stopcombination
\stopplacefigure

\startsubsubsection[title=Where is the convolution?]
In mathematics, the convolution operation is denoted by $*$ and the convolution $s$ of two functions $k$ and $m$ (itself a function) is defined as

\startplaceformula[reference=contconv]
\startformula
s(t) = (k * m)(t) = \int_{{-}\infty}^{{+}\infty} k(x) \cdot m(t-x) \, {\rm d}x
\stopformula
\stopplaceformula
\startplaceformula[reference=discconv]
\startformula
s(i) = (k * m)(i) = \sum_{j = {-}\infty}^{{+}\infty} k(j) \cdot m(i-j)
\stopformula
\stopplaceformula

For continuous (eq.~\in[contconv]) and discrete (eq.~\in[discconv]) functions respectivly.
On a computer, we are in practice always working with discrete convolutions so for us the convolution of interest is eq.~\in[discconv].
If we make the functions $k$ and $m$ two dimentional---they take two indexes as an input---their convolution also becomes two dimentional.

\startplaceformula[reference=twodim-discconv]
\startformula
s(\color[red]{i}, \color[blue]{i}) = (k * m)(\color[red]{i}, \color[blue]{i}) = \sum_{\color[red]{j} = {-}\infty}^{{+}\infty} \sum_{\color[blue]{j} = {-}\infty}^{{+}\infty} k(\color[red]{j}, \color[blue]{j}) \cdot m(\color[red]{i}-\color[red]{j}, \color[blue]{i} - \color[blue]{j})
\stopformula
\stopplaceformula

An assumption that we make when working with finite objects on a computer, is that the parts of the object that does not exists are zero.
Meaning that a finite array can be thought of as an infinte array where all the entries outside of the corresponding finite array are zero.
Pluging such an array into our convolution operation reduces the infinite summation to a finite one.

\startplaceformula[reference=twodim-discconv-finite]
\startformula
s(\color[red]{i}, \color[blue]{i}) = (k * m)(\color[red]{i}, \color[blue]{i}) = \sum_{\color[red]{j} = 1}^{v} \sum_{\color[blue]{j} = 1}^{h} k(\color[red]{j}, \color[blue]{j}) \cdot m(\color[red]{i}-\color[red]{j}, \color[blue]{i} - \color[blue]{j})
\stopformula
\stopplaceformula

\stopsubsubsection

\startsubsubsection[title=Multiple channels]
Let us now add some channels to this neuron.
We will denote the number of channels byb $nC$.
The input and kernel are now multi-channel arrays, their individual entries will be denoted as $K(i,j,c)$.
We have to add the contribution of each channel to the final feature map but we only add the bias once.
Which means that we end up with the following formula

\startplaceformula
\startformula
F(i',j') = {\rm activation} \left( \sum_{i = 1}^{vM} \sum_{j = 1}^{hM} \left( \sum_{c = 1}^{nC} \Bigl( K(i,j,c) \cdot M(i' + i, j + j',c) \right) + b \right)
\stopformula
\stopplaceformula
\stopsubsubsection

\startsubsubsection[title=The stride]
What the stride is and the effects of altering it.
\stopsubsubsection

\startsubsubsection[title=Zero padding]
\stopsubsubsection



\startsubsection[title=The pooling \quote{neuron}]
{\em Downsampling} and purpose of downsampling.
Noise reduction and computational reduction.
\stopsubsection

\startsubsection[title=Backward Propagation]
Obtain formula for derivative of convolution and pooling.
\stopsubsection
\stopsection